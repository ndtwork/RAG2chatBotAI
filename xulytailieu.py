import pdfplumber
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings  # âœ… ÄÃšNG
from langchain_community.vectorstores import FAISS

# ğŸŸ¢ 1. TrÃ­ch xuáº¥t ná»™i dung tá»« PDF
def extract_text_from_pdf(file_path):
    text = ""
    with pdfplumber.open(file_path) as pdf:
        for page in pdf.pages:
            extracted_text = page.extract_text()
            if extracted_text:  # Kiá»ƒm tra náº¿u cÃ³ vÄƒn báº£n
                text += extracted_text + "\n"
    return text

document_text = extract_text_from_pdf("QUYCHE_HUST2023.pdf")
print(document_text[:500])  # Xem trÆ°á»›c 500 kÃ½ tá»± Ä‘áº§u tiÃªn

# ğŸŸ¢ 2. Chia nhá» vÄƒn báº£n thÃ nh cÃ¡c Ä‘oáº¡n nhá»
def split_text(text, chunk_size=500, chunk_overlap=50):
    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    return splitter.split_text(text)

chunks = split_text(document_text)  # ğŸŸ¢ KhÃ´ng bá»‹ ghi Ä‘Ã¨!

print(f"Sá»‘ Ä‘oáº¡n vÄƒn báº£n sau khi chia: {len(chunks)}")

# ğŸŸ¢ 3. Táº¡o vector embeddings tá»« vÄƒn báº£n Ä‘Ã£ xá»­ lÃ½
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vectorstore = FAISS.from_texts(chunks, embeddings)  # ğŸŸ¢ KhÃ´ng dÃ¹ng danh sÃ¡ch máº«u ná»¯a!

# ğŸŸ¢ 4. Truy váº¥n dá»¯ liá»‡u
query = "Quy Ä‘á»‹nh vá» thi cá»­ lÃ  gÃ¬?"
retrieved_docs = vectorstore.similarity_search(query, k=3)

# ğŸŸ¢ 5. Hiá»ƒn thá»‹ káº¿t quáº£ tÃ¬m kiáº¿m
for doc in retrieved_docs:
    print(doc.page_content)
